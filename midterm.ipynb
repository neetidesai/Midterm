{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fce005f",
   "metadata": {},
   "source": [
    "## DS4400 Coding Exam\n",
    "\n",
    "This is the coding exam for DS4400. You have 100 minutes in the lecture. Please write down all the codes and in the Code chuck and written answers in the markdown chuck. Add any chuck if you need. Submit the exam as the homework, with both python and pdf file. The exam is open-book, open notes. Please raise your hand if you have any questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508c28c",
   "metadata": {},
   "source": [
    "#### Question 1: Data analysis\n",
    "In the following question, you will need to analysis a simulated data. Please answer each question below the instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d3c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(4400)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Create 20 random variables\n",
    "X = pd.DataFrame()\n",
    "for i in np.arange(1, 21):\n",
    "    variable_name = f\"Var{i}\"\n",
    "    X[variable_name] = np.random.rand(1000)\n",
    "\n",
    "# Create a target variable based on some combination of the 20 variables\n",
    "y = (\n",
    "    2 * X[\"Var1\"]\n",
    "    + 0.5 * X[\"Var5\"]\n",
    "    - 1 * X[\"Var10\"]\n",
    "    + np.random.normal(0, 0.5, num_samples)  # Add some noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ced033",
   "metadata": {},
   "source": [
    "1. Split the data into training and test data. The proportion of train data should be 70%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b11274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                            y, test_size=0.3, random_state=4400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01306908",
   "metadata": {},
   "source": [
    "2. Fit the model with a linear regression using all the features, report the coefficient table, intercept and MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5171226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) 0.28330490934997343\n",
      "   Feature  Coefficient Estimate\n",
      "0     Var1              2.014028\n",
      "1     Var2             -0.069955\n",
      "2     Var3             -0.118858\n",
      "3     Var4              0.014757\n",
      "4     Var5              0.425563\n",
      "5     Var6              0.022228\n",
      "6     Var7              0.050038\n",
      "7     Var8              0.097579\n",
      "8     Var9             -0.073342\n",
      "9    Var10             -1.096217\n",
      "10   Var11              0.007303\n",
      "11   Var12              0.078436\n",
      "12   Var13              0.025088\n",
      "13   Var14             -0.014747\n",
      "14   Var15             -0.051823\n",
      "15   Var16             -0.034156\n",
      "16   Var17             -0.081478\n",
      "17   Var18              0.126210\n",
      "18   Var19              0.086301\n",
      "19   Var20              0.119386\n",
      "the intercerpt is -0.023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE)\", mse)\n",
    "\n",
    "# coefficients and intercept\n",
    "coef_df = DataFrame(X.columns)\n",
    "coef_df.columns = ['Feature']\n",
    "coef_df[\"Coefficient Estimate\"] = pd.Series(model.coef_)\n",
    "print(coef_df)\n",
    "print(\"the intercerpt is %.3f\" %model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359fcdb",
   "metadata": {},
   "source": [
    "3. Fit the model with a polynomial regression with degree 2, report the MSE. Is it necessary to use polynomial regression in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b96567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) 0.39129598085883716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "degree = 2\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "# Create + fit polynomial regression model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, y_train)\n",
    "\n",
    "X_poly_test = poly_features.fit_transform(X_test)\n",
    "y_poly_test = poly_model.predict(X_poly_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_poly_test)\n",
    "\n",
    "print(\"Mean Squared Error (MSE)\", mse)\n",
    "\n",
    "# No, it is not necessary to use polynomial regression as linear regression has a lower MSE compared to\n",
    "# polynomial regression (0.2833 vs. 0.3913), indicating that linear regression better fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612c560",
   "metadata": {},
   "source": [
    "4. Fit the model with a Lasso regression, tune the parameter for the penalty parameter $\\alpha$. Report the best $\\alpha$, MSE and which variables are left in the model in the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecdcabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.27893476514858456\n",
      "Best alpha 0.01\n",
      "\n",
      "Variables left in model:\n",
      "    Feature  Coefficient Estimate\n",
      "0     Var1              0.566406\n",
      "1     Var2             -0.012671\n",
      "2     Var3             -0.024085\n",
      "4     Var5              0.111930\n",
      "6     Var7              0.008001\n",
      "7     Var8              0.017024\n",
      "8     Var9             -0.013400\n",
      "9    Var10             -0.306822\n",
      "11   Var12              0.012300\n",
      "14   Var15             -0.006134\n",
      "15   Var16             -0.002697\n",
      "16   Var17             -0.016334\n",
      "17   Var18              0.025483\n",
      "18   Var19              0.013672\n",
      "19   Var20              0.024080\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a range of alpha values\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Create a parameter grid for GridSearchCV\n",
    "param_grid = {'alpha': alphas}\n",
    "\n",
    "lasso = Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, \n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Fit Lasso\n",
    "alpha = best_alpha  \n",
    "lasso_model = Lasso(alpha=alpha)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Find selected features (which variables have non-0 coefficients)\n",
    "coef_df = DataFrame(X.columns)\n",
    "coef_df.columns = ['Feature']\n",
    "coef_df[\"Coefficient Estimate\"] = pd.Series(lasso_model.coef_)\n",
    "coef_df.drop(coef_df.loc[coef_df['Coefficient Estimate']==0.000000].index, inplace=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Best alpha\", best_alpha)\n",
    "print(\"\\nVariables left in model:\\n\", coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65e125",
   "metadata": {},
   "source": [
    "5. Define a new target variable $y_1$ such that $y_1$ only contains all the positive values in the $y$. Process $X$ as well. Fit the model with appropriate GLM model (not Gaussian). Report the MSE and can we compare the MSE with previous questions? Hint: it is a continous distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6553dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for gamma distribution:  0.26236130418363884\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(4400)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Create 20 random variables\n",
    "X = pd.DataFrame()\n",
    "for i in np.arange(1, 21):\n",
    "    variable_name = f\"Var{i}\"\n",
    "    X[variable_name] = np.random.rand(1000)\n",
    "\n",
    "# Create a target variable based on some combination of the 20 variables\n",
    "y = (\n",
    "    2 * X[\"Var1\"]\n",
    "    + 0.5 * X[\"Var5\"]\n",
    "    - 1 * X[\"Var10\"]\n",
    "    + np.random.normal(0, 0.5, num_samples)  # Add some noise\n",
    ")\n",
    "\n",
    "\n",
    "negative_index = y.index[y < 0]\n",
    "X = X.drop(negative_index)\n",
    "y = y.drop(negative_index)\n",
    "\n",
    "\n",
    "# fit a gamma model because data is continuous and non negative\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, \n",
    "                                                    random_state = 4400)\n",
    "\n",
    "gamma_model = sm.GLM(y_train, X_train, family = \n",
    "                     sm.families.Gamma(link = sm.families.links.Log()))\n",
    "gamma_results = gamma_model.fit()\n",
    "y_pred_gamma = gamma_results.predict(X_test)\n",
    "mse_gamma = mean_squared_error(y_test, y_pred_gamma)\n",
    "\n",
    "print(\"MSE for gamma distribution: \", mse_gamma)\n",
    "\n",
    "# The MSE for the gamma distribution is very similar to the MSE for linear regression and lasso \n",
    "# (0.2624 vs. 0.2833 vs. 0.2789) and still significantly smaller than the MSE for polynomial \n",
    "# distribution, which was 0.3912, showing Gama model is a good fit for the positive data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1b41b",
   "metadata": {},
   "source": [
    "6. Define a new target variable $y_2$ such that $y_2$ is a binary categorical variable. If $y$ is larger than 1, then $y_2$ is \"group1\", otherwise it is \"group2\". Fit the $y_2$ and $X$ with a logistic regression. Print the summary table with .summary(), and interpret the coefficient for variable 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2274db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Table:\n",
      "                  Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  700\n",
      "Model:                            GLM   Df Residuals:                      680\n",
      "Model Family:                Binomial   Df Model:                           19\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -258.10\n",
      "Date:                Mon, 16 Oct 2023   Deviance:                       516.20\n",
      "Time:                        13:20:27   Pearson chi2:                     556.\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4461\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Var1           7.2567      0.567     12.799      0.000       6.145       8.368\n",
      "Var2          -0.9664      0.388     -2.490      0.013      -1.727      -0.206\n",
      "Var3          -0.8041      0.391     -2.055      0.040      -1.571      -0.037\n",
      "Var4          -0.0219      0.382     -0.057      0.954      -0.771       0.727\n",
      "Var5           1.4116      0.381      3.706      0.000       0.665       2.158\n",
      "Var6          -0.4603      0.373     -1.233      0.217      -1.192       0.271\n",
      "Var7           0.5581      0.383      1.456      0.145      -0.193       1.309\n",
      "Var8          -0.3356      0.398     -0.842      0.400      -1.117       0.445\n",
      "Var9          -0.6660      0.376     -1.771      0.077      -1.403       0.071\n",
      "Var10         -4.1833      0.459     -9.115      0.000      -5.083      -3.284\n",
      "Var11         -0.0303      0.369     -0.082      0.935      -0.753       0.693\n",
      "Var12         -1.0341      0.385     -2.688      0.007      -1.788      -0.280\n",
      "Var13         -0.7372      0.384     -1.918      0.055      -1.491       0.016\n",
      "Var14         -0.1698      0.375     -0.453      0.651      -0.905       0.565\n",
      "Var15         -0.3714      0.372     -0.999      0.318      -1.100       0.358\n",
      "Var16         -0.8353      0.383     -2.178      0.029      -1.587      -0.084\n",
      "Var17         -1.0418      0.384     -2.715      0.007      -1.794      -0.290\n",
      "Var18          0.7710      0.399      1.934      0.053      -0.011       1.553\n",
      "Var19         -0.3831      0.383     -1.001      0.317      -1.133       0.367\n",
      "Var20          0.4274      0.389      1.097      0.272      -0.336       1.191\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(4400)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Create 20 random variables\n",
    "X = pd.DataFrame()\n",
    "for i in np.arange(1, 21):\n",
    "    variable_name = f\"Var{i}\"\n",
    "    X[variable_name] = np.random.rand(1000)\n",
    "\n",
    "# Create a target variable based on some combination of the 20 variables\n",
    "y = (\n",
    "    2 * X[\"Var1\"]\n",
    "    + 0.5 * X[\"Var5\"]\n",
    "    - 1 * X[\"Var10\"]\n",
    "    + np.random.normal(0, 0.5, num_samples)  # Add some noise\n",
    ")\n",
    "\n",
    "# create y2\n",
    "above_1_index = y.index[y > 1]\n",
    "below_1_index = y.index[y <= 1]\n",
    "\n",
    "y2 = (y > 1).astype(int)\n",
    "\n",
    "\n",
    "# fit logistic regression model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size = 0.3, \n",
    "                                                    random_state = 4400)\n",
    "\n",
    "model = sm.GLM(y_train, X_train, family = sm.families.Binomial())\n",
    "results = model.fit()\n",
    "y_pred = results.predict(X_test)\n",
    "\n",
    "print(\"Summary Table:\\n\", results.summary())\n",
    "\n",
    "# The coefficient for Var1 is 7.2567. This means with a one unit increase in Var1, there is a 7.2567 unit\n",
    "# increase in the target value. Since the coefficeint of Var1 is positive, that means there is a positive\n",
    "# relationship between Var1 and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51d310",
   "metadata": {},
   "source": [
    "#### Question 2: Implement Gradient descend for Polynomial Regression\n",
    "\n",
    "Implement gradient descend method for the polynomial regression. Requirement: \n",
    "1. Write the method as a function, which is given here. Notice that it takes an input \"degree\" (and any other necessary inputs) so that we can change the degree of the polynomial. \n",
    "2. Output the cost history as well as the coefficient estimates. No need to print it or make the figures. As long as it is one of the output. \n",
    "3. Verify your function with the data in Question 1 (You may need to copy/paste and run the answer in Question 1-1 before you run the verification). No need to compare your coefficients to the ones in question 1. This step is only to make sure your functions work. You can set the degree as 2 in the verification. \n",
    "\n",
    "Hint: \n",
    "1. Don't overthinking the question. What is the difference between linear regression and polynomial regression?\n",
    "2. You may need two functions here. One for pre-processing the data, while the other one for gradient desent. You can add more if you need. Like to add another one for the cost function. \n",
    "3. When initializing the theta, think about how many coefficients you may need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e26a2a-1724-45ae-8314-811e4f3a64ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1aa9662f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (700, 700) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Initialize model parameters (coefficients)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(X_poly\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_poly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(g)\n",
      "Cell \u001b[0;32mIn[77], line 19\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(X, y, num_iterations, learning_rate, degree, theta)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m     18\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, theta)\n\u001b[0;32m---> 19\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\n\u001b[1;32m     20\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mn) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mT, error)\n\u001b[1;32m     21\u001b[0m     theta \u001b[38;5;241m=\u001b[39m theta \u001b[38;5;241m+\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradient\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:5820\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5819\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 5820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/base.py:1383\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:5916\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   5914\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   5915\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 5916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5917\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5919\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   5920\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    510\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/construction.py:636\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    633\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[1;32m    634\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 636\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    640\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/construction.py:695\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    697\u001b[0m     )\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (700, 700) instead"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def poly_function(degree, X):\n",
    "    \n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    \n",
    "    return X_poly\n",
    "    \n",
    "def gradient_descent(X, y, num_iterations, learning_rate, degree, theta):\n",
    "    # gradient descent\n",
    "    n = len(y)\n",
    "    cost_history = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        predictions = np.dot(X, theta)\n",
    "        error = y - predictions\n",
    "        gradient = (-2/n) * np.dot(X.T, error)\n",
    "        theta = theta + learning_rate * gradient\n",
    "        cost = np.mean(np.square(error))  \n",
    "        cost_history.append(cost)\n",
    "        \n",
    "    return theta, cost_history\n",
    "\n",
    "\n",
    "#Verification\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                            y, test_size=0.3, random_state=4400)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "degree = 2\n",
    "\n",
    "X_poly = poly_function(degree, X_train)\n",
    "\n",
    "# Initialize model parameters (coefficients)\n",
    "theta = np.random.randn(X_poly.shape[1], 1)\n",
    "\n",
    "g = gradient_descent(X_poly, y_train, num_iterations, learning_rate, degree, theta)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b738e7",
   "metadata": {},
   "source": [
    "#### Question 3: Simulation study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af4348",
   "metadata": {},
   "source": [
    "Following is a simulation study. In the second code chuck, please correctly label the xlabel and ylabel for the plot. Also explain what this code is trying to do and what you have learned from the generated figure. \n",
    "\n",
    "Hint: in the simulation data, there are 200 observations and it is fixed for each trial. After spliting the training and testing data, each one will have 100 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddef77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(83)\n",
    "A = np.arange(5,101,1)\n",
    "B = []\n",
    "\n",
    "# for every element p in A\n",
    "for p in A:\n",
    "\n",
    "    # create DataFrame X\n",
    "    X = pd.DataFrame()\n",
    "\n",
    "    # for i from 1 to p\n",
    "    for i in np.arange(1, p+1):\n",
    "\n",
    "        # create a new variable i\n",
    "        variable_name = f\"Var{i}\"\n",
    "\n",
    "        # For variable i in X, create a random array of 200 numbers, with each number ranging from 0 to 1\n",
    "        X[variable_name] = np.random.rand(200)\n",
    "\n",
    "    # y is defined as 2 * \n",
    "    # the random array of numbers for Var1 stored in X - \n",
    "    # 0.5 * the random array of numbers for Var5 stored in X +\n",
    "    # a random array of 200 numbers with mean 0 and standard distribution 0.5\n",
    "    y = 2 * X[\"Var1\"] - 0.5 * X[\"Var5\"] + np.random.normal(0, 0.5, 200)\n",
    "\n",
    "    \n",
    "    # train test split X and y with test size = 50% of data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.5, \n",
    "                                                        random_state=83)\n",
    "    # create linear regression model\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # fit linear regression model\n",
    "    lm.fit(X_train, y_train)\n",
    "\n",
    "    # predict y values\n",
    "    y_pred = lm.predict(X_test)\n",
    "\n",
    "    # find MSE\n",
    "    value = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # append MSE to B\n",
    "    B.append(value)\n",
    "\n",
    "# see comments in function for detailed analysis of code chunk\n",
    "# Summary: for every number p in A (from 5 to 100), create dataframe X with 200 rows and p columns.\n",
    "    # so, for every iteration of outer for loop (every increase of p), the number of columns in X\n",
    "    # will increase.\n",
    "# create y by multiplying X[0] by 2, then subtracting 0.5 * x[4], and finally adding\n",
    "# a random array of 200 numbers - size of y stays the same for all values of p\n",
    "# Train test split the X, y data and create a linear regression model\n",
    "# fit the model with X_train, y_train, then predict y values\n",
    "# calculate MSE and append MSE to array B\n",
    "# plot A vs. B\n",
    "# analysis of graph: as number of columns in X increases (as p gets larger), MSE of \n",
    "# linear regression model increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4654def2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(A, B)\n",
    "plt.xlabel(\"Number of Columns\")\n",
    "plt.ylabel(\"MSE for Linear Regression of Data With Size 200xA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e19004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
